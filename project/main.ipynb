{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Load and Wearable Integration Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files and Data Relationship Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# def visualize_csv(csv_path):\n",
    "#     # Read CSV file\n",
    "#     df = pd.read_csv(csv_path)\n",
    "\n",
    "#     # Plot the data\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     for column in df.columns:\n",
    "#         if column != \"time\":\n",
    "#             plt.plot(df[\"time\"], df[column], label=column)\n",
    "#     plt.xlabel(\"Time\")\n",
    "#     plt.ylabel(\"Value\")\n",
    "#     plt.title(\"Data from {}\".format(os.path.basename(csv_path)))\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def process_directory(root_dir):\n",
    "#     for subdir, dirs, files in os.walk(root_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith(\".csv\") and (\n",
    "#                 \"empatica\" in file.lower() or \"samsung\" in file.lower()\n",
    "#             ):\n",
    "#                 csv_path = os.path.join(subdir, file)\n",
    "#                 try:\n",
    "#                     visualize_csv(csv_path)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing file {csv_path}: {e}\")\n",
    "\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     root_directory = \"./data/cogwear\"\n",
    "# #     process_directory(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# def process_directory(root_dir, output_file):\n",
    "#     # Create an empty list to store aggregated data\n",
    "#     agg_data = []\n",
    "\n",
    "#     # Iterate through the participant directories\n",
    "#     for participant_dir in os.listdir(root_dir):\n",
    "#         participant_id = (\n",
    "#             participant_dir  # Participant ID is the name of the subdirectory\n",
    "#         )\n",
    "\n",
    "#         # Iterate through the subdirectories (baseline and cognitive_load)\n",
    "#         for sub_dir in [\"baseline\", \"cognitive_load\"]:\n",
    "#             sub_dir_path = os.path.join(root_dir, participant_dir, sub_dir)\n",
    "\n",
    "#             # Check if the path is a directory\n",
    "#             if os.path.isdir(sub_dir_path):\n",
    "#                 # Get the cognitive load label\n",
    "#                 cl = 0 if sub_dir == \"baseline\" else 1\n",
    "\n",
    "#                 # Iterate through the files in the subdirectory\n",
    "#                 for file in os.listdir(sub_dir_path):\n",
    "#                     if file.endswith(\".csv\") and file.startswith(\n",
    "#                         (\"empatica_bvp\", \"empatica_eda\", \"empatica_temp\", \"samsung_bvp\")\n",
    "#                     ):\n",
    "#                         file_path = os.path.join(sub_dir_path, file)\n",
    "#                         df = pd.read_csv(file_path)\n",
    "#                         # Extract relevant data and append to the aggregated list\n",
    "#                         for _, row in df.iterrows():\n",
    "#                             agg_data.append(\n",
    "#                                 {\n",
    "#                                     \"participant_id\": participant_id,\n",
    "#                                     \"empatica_bvp\": row.get(\"bvp\"),\n",
    "#                                     \"empatica_bvp_time\": (\n",
    "#                                         row.get(\"time\")\n",
    "#                                         if \"empatica_bvp\" in file\n",
    "#                                         else None\n",
    "#                                     ),\n",
    "#                                     \"empatica_eda\": row.get(\"eda\"),\n",
    "#                                     \"empatica_eda_time\": (\n",
    "#                                         row.get(\"time\")\n",
    "#                                         if \"empatica_eda\" in file\n",
    "#                                         else None\n",
    "#                                     ),\n",
    "#                                     \"empatica_temp\": row.get(\"temp\"),\n",
    "#                                     \"empatica_temp_time\": (\n",
    "#                                         row.get(\"time\")\n",
    "#                                         if \"empatica_temp\" in file\n",
    "#                                         else None\n",
    "#                                     ),\n",
    "#                                     \"samsung_bvp\": row.get(\"PPG GREEN\"),\n",
    "#                                     \"samsung_bvp_time\": (\n",
    "#                                         row.get(\"time\")\n",
    "#                                         if \"samsung_bvp\" in file\n",
    "#                                         else None\n",
    "#                                     ),\n",
    "#                                     \"CL\": cl,\n",
    "#                                 }\n",
    "#                             )\n",
    "\n",
    "#     # Create a DataFrame from the aggregated data\n",
    "#     agg_df = pd.DataFrame(agg_data)\n",
    "\n",
    "#     # Write aggregated DataFrame to CSV file\n",
    "#     agg_df.to_csv(output_file, index=False)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     root_directory = \"./data/cogwear/pilot\"\n",
    "#     output_file = \"./data/processed/cogwear-agg.csv\"\n",
    "#     process_directory(root_directory, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def aggregate_by_time(df):\n",
    "    # Create an empty list to store aggregated data\n",
    "    agg_data = []\n",
    "\n",
    "    # Iterate over each participant\n",
    "    for participant_id in df[\"participant_id\"].unique():\n",
    "        participant_df = df[df[\"participant_id\"] == participant_id]\n",
    "\n",
    "        # Iterate over each time sequence\n",
    "        min_time = participant_df[\"empatica_bvp_time\"].min()\n",
    "        max_time = participant_df[\"empatica_bvp_time\"].max()\n",
    "        intervals = np.arange(min_time, max_time + 5, 5)\n",
    "\n",
    "        for interval_start, interval_end in zip(intervals[:-1], intervals[1:]):\n",
    "            interval_data = {\"participant_id\": participant_id}\n",
    "\n",
    "            for column in [\n",
    "                \"empatica_bvp\",\n",
    "                \"empatica_eda\",\n",
    "                \"empatica_temp\",\n",
    "                \"samsung_bvp\",\n",
    "            ]:\n",
    "                interval_values = participant_df[\n",
    "                    (participant_df[\"empatica_bvp_time\"] >= interval_start)\n",
    "                    & (participant_df[\"empatica_bvp_time\"] < interval_end)\n",
    "                ][column].tolist()\n",
    "                if interval_values:\n",
    "                    interval_data[column] = interval_values\n",
    "                    interval_data[column + \"_time\"] = [interval_start] * len(\n",
    "                        interval_values\n",
    "                    )\n",
    "\n",
    "            if interval_data:  # Check if interval_data is not empty\n",
    "                agg_data.append(interval_data)\n",
    "\n",
    "    # Create DataFrame from aggregated data\n",
    "    agg_df = pd.DataFrame(agg_data)\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the existing cogwear-agg.csv\n",
    "    cogwear_df = pd.read_csv(\"./data/processed/cogwear-agg.csv\")\n",
    "\n",
    "    # Aggregate the data by time sequences and participant IDs\n",
    "    aggregated_df = aggregate_by_time(cogwear_df)\n",
    "\n",
    "    # Write the aggregated data to a new CSV file\n",
    "    aggregated_df.to_csv(\"./data/processed/cogwear-agg-time-secv.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
